# ğŸ¤– KODECAMP 5X Machine Learning Core

A comprehensive machine learning bootcamp journey covering foundational concepts to advanced deep learning techniques.

## ğŸ“š Course Overview

This repository contains assignments, notes, and projects from the **KODECAMP 5X Machine Learning Core** bootcamp program. The curriculum spans 13 weeks of intensive learning, progressing from machine learning fundamentals through advanced neural networks, transformers, and reinforcement learning.

**GitHub Repository:** [Erickpython/kodeCamp_5X-MachineLearning](https://github.com/Erickpython/kodeCamp_5X-MachineLearning)

## ğŸ“– Curriculum Structure

### **Week 1: Introduction to Machine Learning**
*6 topics â€¢ 4 hours*
- Fundamentals of ML concepts and paradigms
- Problem framing and evaluation metrics
- Data preprocessing essentials

### **Week 2: Regression & Classification**
*7 topics â€¢ 4 hours*
- Linear and logistic regression
- Classification algorithms and metrics
- Model evaluation and validation techniques

### **Week 3: Classical Machine Learning Algorithms**
*3 topics â€¢ 4 hours*
- Decision trees and ensemble methods
- Support vector machines (SVM)
- Algorithm comparison and selection

### **Week 4: Unsupervised and Self-Supervised Learning**
*4 topics â€¢ 4 hours*
- Clustering algorithms (K-means, hierarchical clustering)
- Dimensionality reduction (PCA)
- Self-supervised learning approaches

### **Week 5: Neural Network Fundamentals**
*4 topics â€¢ 4 hours*
- Perceptrons and multilayer networks
- Backpropagation algorithm
- Activation functions and network architecture design

### **Week 6: Optimization & Training Dynamics**
*3 topics â€¢ 4 hours*
- Gradient descent variants (SGD, Adam, RMSprop)
- Regularization techniques
- Hyperparameter tuning and learning curves

### **Week 7: Convolutional Neural Networks**
*5 topics â€¢ 4 hours*
- Convolution operations and architecture design
- Popular CNN architectures (VGG, ResNet, Inception)
- Computer vision applications

### **Week 8: Sequence Models**
*3 topics â€¢ 4 hours*
- Recurrent neural networks (RNN, LSTM, GRU)
- Sequence modeling and time series prediction
- Natural language processing basics

### **Week 9: Attention Mechanisms & Transformers**
*4 topics â€¢ 4 hours*
- Attention mechanism theory and implementation
- Transformer architecture
- Self-attention and multi-head attention

### **Week 10: Large Language Models**
*5 topics â€¢ 4 hours*
- Transfer learning and pre-trained models
- Fine-tuning LLMs
- Prompt engineering and applications

### **Week 11: Generative Models**
*3 topics â€¢ 4 hours*
- Variational autoencoders (VAE)
- Generative adversarial networks (GAN)
- Diffusion models

### **Week 12: Reinforcement Learning and Scaling Up**
*3 topics â€¢ 4 hours*
- Markov decision processes
- Q-learning and policy gradient methods
- Multi-agent systems and scaling strategies

### **Week 13: Capstone Project**
Comprehensive project applying learned concepts to real-world problems

---

## ğŸ“ Repository Structure

```
kodeCamp_5X-MachineLearning/
â”œâ”€â”€ README.md                                      # Course overview and documentation
â”œâ”€â”€ requirements.txt                               # Python dependencies
â”œâ”€â”€ assignments/                                   # Weekly assignments and implementations
â”‚   â”œâ”€â”€ FeatureEngineering_Task3_Assignment.ipynb
â”‚   â”œâ”€â”€ LinearRegressionML.ipynb
â”‚   â”œâ”€â”€ LinearRegression_GradientDescent.ipynb
â”‚   â”œâ”€â”€ Logistic_Regression_with_Multiple_Variables.ipynb
â”‚   â”œâ”€â”€ MultivariableLinearRegression.ipynb
â”‚   â””â”€â”€ TASK3_LogisticRegression.ipynb
â”œâ”€â”€ lecture_notes/                                 # Learning materials and lecture notebooks
â”‚   â”œâ”€â”€ Feature_Engineering.ipynb
â”‚   â”œâ”€â”€ Lecture_Note_Logistic_Regression.ipynb
â”‚   â”œâ”€â”€ Random_Forest_with_SkLearn.ipynb
â”‚   â””â”€â”€ SVM_With_SkLearn.ipynb
â””â”€â”€ kodecampvenv/                                 # Python virtual environment
```

## ğŸ› ï¸ Technology Stack

- **Language:** Python 3.12
- **Core Libraries:**
  - NumPy - Numerical computing
  - Pandas - Data manipulation and analysis
  - Scikit-learn - Classical machine learning algorithms
  - TensorFlow/Keras - Deep learning framework
  - Jupyter - Interactive notebooks for learning and experimentation
  - Matplotlib/Seaborn - Data visualization

## ğŸš€ Getting Started

### Prerequisites
- Python 3.12 or higher
- Virtual environment manager (venv)
- Git

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/Erickpython/kodeCamp_5X-MachineLearning.git
   cd kodeCamp_5X-MachineLearning
   ```

2. **Activate the virtual environment:**
   ```bash
   source kodecampvenv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Launch Jupyter Notebook:**
   ```bash
   jupyter notebook
   ```

## ğŸ“ Learning Path

This bootcamp follows a structured progression:

1. **Foundation** (Weeks 1-2): Master ML basics and core regression/classification concepts
2. **Classical ML** (Weeks 3-4): Explore traditional algorithms and unsupervised learning
3. **Neural Networks** (Weeks 5-6): Deep dive into neural network fundamentals and optimization
4. **Advanced Deep Learning** (Weeks 7-8): CNNs for vision and RNNs for sequences
5. **Modern Architectures** (Weeks 9-10): Transformers and large language models
6. **Cutting-Edge Topics** (Weeks 11-12): Generative models and reinforcement learning
7. **Capstone** (Week 13): Apply all knowledge to solve real-world problems

## ğŸ“Š Key Topics Covered

- âœ… Supervised & Unsupervised Learning
- âœ… Neural Networks & Deep Learning
- âœ… Computer Vision (CNNs)
- âœ… Natural Language Processing (RNNs, Transformers)
- âœ… Large Language Models (LLMs)
- âœ… Generative Models (VAEs, GANs, Diffusion)
- âœ… Reinforcement Learning
- âœ… Model Optimization & Training Strategies
- âœ… Feature Engineering & Data Preprocessing

## ğŸ’¡ How to Use This Repository

- **Assignments:** Review and run notebook files in the `assignments/` folder to see implementations of course concepts
- **Lecture Notes:** Study the `lecture_notes/` folder for additional learning materials and explanations
- **Experimentation:** Use Jupyter notebooks for hands-on practice and experimentation
- **Challenges:** Complete exercises and apply concepts to new datasets

## ğŸ¯ Learning Outcomes

Upon completion of this bootcamp, you will be able to:

- Understand foundational ML theory and best practices
- Implement classical and modern ML algorithms
- Build and train neural networks from scratch
- Work with CNNs for computer vision tasks
- Implement sequence models for NLP
- Understand and apply transformer architectures
- Fine-tune and deploy large language models
- Explore generative and reinforcement learning
- Solve real-world ML problems with proper evaluation metrics

## ğŸ“š Additional Resources

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [TensorFlow/Keras Guide](https://www.tensorflow.org/)
- [Fast.ai Machine Learning Course](https://course.fast.ai/)
- [Stanford CS229 - Machine Learning](http://cs229.stanford.edu/)

## ğŸ“§ Contact

For questions or discussions about the course material, feel free to open an issue on the GitHub repository.

---

**Last Updated:** December 2024  
**Status:** ğŸš€ In Progress - Week 1 onwards  
**License:** MIT